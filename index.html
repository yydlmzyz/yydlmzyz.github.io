<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-169048535-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-169048535-1');
  </script>

  <title>Dingquan Li</title>
  
  <meta name="author" content="Jianqiang Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jianqiang Wang</name>
              </p>
              <p>
                I am a Ph.D student at <a href="https://vision.nju.edu.cn/main.htm">Nanjing University</a>, where I am advised by Prof. Zhan Ma. I received the B.S. and M.S. degrees in electronic science and engineering from Nanjing University, in 2018 and 2021. My research interests include point cloud compression and deep learning.
              </p>
              <p style="text-align:center">
                <a href="mailto:wangjq@smail.nju.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/Jianqiang-CV.pdf">CV</a>;<a href="data/Jianqiang-CV_cn.pdf">CV_cn</a> &nbsp/&nbsp
                <!-- <a href="data/DingquanLi-bio.txt">Biography</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?hl=en&user=75eYktgAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/yydlmzyz"> Github </a> &nbsp/&nbsp
                <a href="https://www.researchgate.net/profile/Jianqiang-Wang-21"> ResearchGate </a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jianqiang-wang-b455631a5/"> Linkedin </a> 
              </p>
            </td>
            <!-- <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Jianqiang.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Jianqiang.jpeg" class="hoverZoomLink"></a>
            </td> -->
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>My main interest lies in image processing and computer vision, including:</p>
              <ul>
                <li>3D Point Cloud Compression</li>
                <li>Image/Video Compression</li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9968173">
                <papertitle>Sparse Tensor-Based Multiscale Representation for Point Cloud Geometry Compression</papertitle>
              </a>
              <br>
              <strong>Jianqiang Wang</strong>, 
              <a href='https://scholar.google.com/citations?user=pGImcC8AAAAJ&hl=en&oi=ao'>Dandan Ding</a>, 
              <a href='http://l.web.umkc.edu/lizhu/'>Zhu Li</a>,
              Xiaoxing Feng,
              Chuntong Cao,
              <a href='https://vision.nju.edu.cn/fc/d3/c29470a457939/page.htm'>Zhan Ma*</a>
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2023. &nbsp <font color="red"><strong>(SCI JCR Q1, IF=24.314; CCF A)</strong></font>
              <br>
              <a href="https://github.com/NJUVISION/SparsePCGC">code</a> 
              <p>A unified Point Cloud Geometry (PCG) compression method through the processing of multiscale sparse tensor-based voxelized point cloud.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9321375">
                <papertitle>Lossy Point Cloud Geometry Compression via End-to-End Learning</papertitle>
              </a>
              <br>
              <strong>Jianqiang Wang</strong>, 
              <a href='http://zhuhao.cc/home/'>Hao Zhu</a>, 
              <a href='https://scholar.google.com/citations?hl=en&user=nYENH40AAAAJ'>Haojie Liu</a>,
              <a href='https://vision.nju.edu.cn/fc/d3/c29470a457939/page.htm'>Zhan Ma*</a>
              <br>
              <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em>, 2021. &nbsp <font color="red"><strong>(SCI JCR Q1, IF=8.4; CCF B)</strong></font>  &nbsp <font color="red"><strong>(2023 IEEE CAS Society Outstanding Young Author Award)</strong></font>
              <br>
              <a href="https://github.com/NJUVISION/PCGCv1">code</a> /
              <a href="https://youtu.be/c5T2kUrxUEc?si=F_l6GxZv_LxBLmJO">video</a>  
              <p>A novel end-to-end Learned Point Cloud Geometry Compression framework.</p>
            </td>
          </tr>

<!-- 
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="http://www.vie.group/media/pdf/08489929.pdf">
                <papertitle>Which Has Better Visual Quality: The Clear Blue Sky or a Blurry Animal?</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='https://www.ntu.edu.sg/home/wslin/'>Weisi Lin</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>IEEE Transactions on Multimedia (TMM)</em>, 2019 &nbsp <font color="red"><strong>(SCI JCR Q1, IF=5.452; CCF B)</strong></font>
              <br>
              <a href="http://www.vie.group/media/pdf/PKU-NTU_Workshop_Macau2018-TMM_presentation.pdf">slides</a> / 
              <a href="https://github.com/lidq92/SFA">code</a> 
              <a class="btn btn-sm btn-with-count  tooltipped tooltipped-s" aria-label="You must be signed in to star a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:119025388,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/SFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="64dbd292aea623b947e07b7c45d52562a7ced9e01acf39fbdff1a0ec328c74da" href="https://github.com/login?return_to=%2Flidq92%2FSFA">
                <svg height="16" class="octicon octicon-star v-align-text-bottom" vertical_align="text_bottom" viewBox="0 0 16 16" version="1.1" width="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 .25a.75.75 0 01.673.418l1.882 3.815 4.21.612a.75.75 0 01.416 1.279l-3.046 2.97.719 4.192a.75.75 0 01-1.088.791L8 12.347l-3.766 1.98a.75.75 0 01-1.088-.79l.72-4.194L.818 6.374a.75.75 0 01.416-1.28l4.21-.611L7.327.668A.75.75 0 018 .25zm0 2.445L6.615 5.5a.75.75 0 01-.564.41l-3.097.45 2.24 2.184a.75.75 0 01.216.664l-.528 3.084 2.769-1.456a.75.75 0 01.698 0l2.77 1.456-.53-3.084a.75.75 0 01.216-.664l2.24-2.183-3.096-.45a.75.75 0 01-.564-.41L8 2.694v.001z"></path></svg></a> 
              <a class="social-count js-social-count" href="https://github.com/lidq92/SFA/stargazers" aria-label="51 users starred this repository">51</a>
              <a class="btn btn-sm btn-with-count tooltipped tooltipped-s" aria-label="You must be signed in to fork a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:119025388,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/SFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="f510e148b10d64ff451ad2e95a4b503ebf752ccab702aa1262d778f3d5665b5e" href="https://github.com/login?return_to=%2Flidq92%2FSFA">
                <svg class="octicon octicon-repo-forked" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"></path></svg></a>
              <a href="https://github.com/lidq92/SFA/network/members" class="social-count" aria-label="13 users forked this repository">13</a> /
              <a href="data/LiTMM2019.bib">bibtex</a>
              <p></p>
              <p>Most conventional objective metrics prefer blurry animals (relatively complex visual content) over clear the blue sky (simple content), contradicting with human perception: content-aware features help ...</p>
            </td>
          </tr> -->
<!-- 
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2008.03889">
                <papertitle>Norm-in-Norm Loss with Faster Convergence and Better Performance for Image Quality Assessment</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>ACM International Conference on Multimedia (MM)</em>, 2020 &nbsp <font color="red"><strong>(Oral, CCF A)</strong></font>
              <br>
              <a href="http://www.vie.group/media/pdf/MM20-fp0612.mp4">video</a> / 
              <a href="http://www.vie.group/media/pdf/MM20-fp0612-one-slide.pdf">poster</a> / 
              <a href="https://github.com/lidq92/LinearityIQA">code</a> 
              <a class="btn btn-sm btn-with-count  tooltipped tooltipped-s" aria-label="You must be signed in to star a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:284060958,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/LinearityIQA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="82661f29a63200e6079465d3303bb73ac22117ccdb7701103f144fa58b3dd68d" href="https://github.com/login?return_to=%2Flidq92%2FLinearityIQA">
                <svg vertical_align="text_bottom" height="16" class="octicon octicon-star v-align-text-bottom" viewBox="0 0 16 16" version="1.1" width="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 .25a.75.75 0 01.673.418l1.882 3.815 4.21.612a.75.75 0 01.416 1.279l-3.046 2.97.719 4.192a.75.75 0 01-1.088.791L8 12.347l-3.766 1.98a.75.75 0 01-1.088-.79l.72-4.194L.818 6.374a.75.75 0 01.416-1.28l4.21-.611L7.327.668A.75.75 0 018 .25zm0 2.445L6.615 5.5a.75.75 0 01-.564.41l-3.097.45 2.24 2.184a.75.75 0 01.216.664l-.528 3.084 2.769-1.456a.75.75 0 01.698 0l2.77 1.456-.53-3.084a.75.75 0 01.216-.664l2.24-2.183-3.096-.45a.75.75 0 01-.564-.41L8 2.694v.001z"></path></svg>
              </a>
              <a class="social-count js-social-count" href="https://github.com/lidq92/LinearityIQA/stargazers" aria-label="38 users starred this repository">38</a>
              <a class="btn btn-sm btn-with-count tooltipped tooltipped-s" aria-label="You must be signed in to fork a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:284060958,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/LinearityIQA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="c5f532420a3db3c7f552dc0f781442c75456f7379abf9192a6e067e4f5c6eb38" href="https://github.com/login?return_to=%2Flidq92%2FLinearityIQA">
                <svg class="octicon octicon-repo-forked" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"></path></svg>
              </a>
              <a href="https://github.com/lidq92/LinearityIQA/network/members" class="social-count" aria-label="10 users forked this repository">10</a>
              /
              <a href="data/LiACMMM2020.bib">bibtex</a>
              <p></p>
              <p>Normalization-embedded loss is conducive to the faster convergence and better performance of the IQA model.</p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1908.00375">
                <papertitle>Quality Assessment of In-the-Wild Videos</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>ACM International Conference on Multimedia (MM)</em>, 2019 &nbsp <font color="red"><strong>(Oral, CCF A)</strong></font>
              <br>
              <a href="http://www.vie.group/media/pdf/P5B-01_presentation_with_videos.pptx">slides</a> / 
              <a href="http://www.vie.group/media/pdf/P5B-01.pdf">poster</a> / 
              <a href="https://github.com/lidq92/VSFA">code</a> 
              <a class="btn btn-sm btn-with-count  tooltipped tooltipped-s" aria-label="You must be signed in to star a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:195149316,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/VSFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="dc4afc52face7c58e577d0aeafea161ddbbf4de0008fc9ff1784c4bafefabe44" href="https://github.com/login?return_to=%2Flidq92%2FVSFA"><svg height="16" class="octicon octicon-star v-align-text-bottom" vertical_align="text_bottom" viewBox="0 0 16 16" version="1.1" width="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 .25a.75.75 0 01.673.418l1.882 3.815 4.21.612a.75.75 0 01.416 1.279l-3.046 2.97.719 4.192a.75.75 0 01-1.088.791L8 12.347l-3.766 1.98a.75.75 0 01-1.088-.79l.72-4.194L.818 6.374a.75.75 0 01.416-1.28l4.21-.611L7.327.668A.75.75 0 018 .25zm0 2.445L6.615 5.5a.75.75 0 01-.564.41l-3.097.45 2.24 2.184a.75.75 0 01.216.664l-.528 3.084 2.769-1.456a.75.75 0 01.698 0l2.77 1.456-.53-3.084a.75.75 0 01.216-.664l2.24-2.183-3.096-.45a.75.75 0 01-.564-.41L8 2.694v.001z"></path></svg></a>
              <a class="social-count js-social-count" href="https://github.com/lidq92/VSFA/stargazers" aria-label="112 users starred this repository">112</a> 
              <a class="btn btn-sm btn-with-count tooltipped tooltipped-s" aria-label="You must be signed in to fork a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:195149316,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/VSFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="04588d4b5f022392ef24a2c5520a75ed086ed2f4a9997e13901732d35a553f0c" href="https://github.com/login?return_to=%2Flidq92%2FVSFA">
                <svg class="octicon octicon-repo-forked" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"></path></svg></a>
              <a href="https://github.com/lidq92/VSFA/network/members" class="social-count" aria-label="29 users forked this repository">29</a> /
              <a href="data/LiACMMM2019.bib">bibtex</a>
              <p></p>
              <p>Content dependency and temporal-memory effects of HVS are considered in the design of NR-VQA models.</p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1810.08169">
                <papertitle>Exploiting High-Level Semantics for No-Reference Image Quality Assessment of Realistic Blur Images</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>ACM International Conference on Multimedia (MM)</em>, 2017 &nbsp <font color="red"><strong>(CCF A)</strong></font>
              <br>
              <a href="http://www.vie.group/media/pdf/frp303-fast_forward.pptx">slides</a> / 
              <a href="http://www.vie.group/media/pdf/acmmm17_poster-updated_3BofFhr.pdf">poster</a> / 
              <a href="https://github.com/lidq92/SFA">code</a> 
              <a class="btn btn-sm btn-with-count  tooltipped tooltipped-s" aria-label="You must be signed in to star a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:119025388,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/SFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="64dbd292aea623b947e07b7c45d52562a7ced9e01acf39fbdff1a0ec328c74da" href="https://github.com/login?return_to=%2Flidq92%2FSFA">
                <svg height="16" class="octicon octicon-star v-align-text-bottom" vertical_align="text_bottom" viewBox="0 0 16 16" version="1.1" width="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 .25a.75.75 0 01.673.418l1.882 3.815 4.21.612a.75.75 0 01.416 1.279l-3.046 2.97.719 4.192a.75.75 0 01-1.088.791L8 12.347l-3.766 1.98a.75.75 0 01-1.088-.79l.72-4.194L.818 6.374a.75.75 0 01.416-1.28l4.21-.611L7.327.668A.75.75 0 018 .25zm0 2.445L6.615 5.5a.75.75 0 01-.564.41l-3.097.45 2.24 2.184a.75.75 0 01.216.664l-.528 3.084 2.769-1.456a.75.75 0 01.698 0l2.77 1.456-.53-3.084a.75.75 0 01.216-.664l2.24-2.183-3.096-.45a.75.75 0 01-.564-.41L8 2.694v.001z"></path></svg></a> 
              <a class="social-count js-social-count" href="https://github.com/lidq92/SFA/stargazers" aria-label="51 users starred this repository">51</a>
              <a class="btn btn-sm btn-with-count tooltipped tooltipped-s" aria-label="You must be signed in to fork a repository" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:119025388,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/lidq92/SFA&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="f510e148b10d64ff451ad2e95a4b503ebf752ccab702aa1262d778f3d5665b5e" href="https://github.com/login?return_to=%2Flidq92%2FSFA">
                <svg class="octicon octicon-repo-forked" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M5 3.25a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm0 2.122a2.25 2.25 0 10-1.5 0v.878A2.25 2.25 0 005.75 8.5h1.5v2.128a2.251 2.251 0 101.5 0V8.5h1.5a2.25 2.25 0 002.25-2.25v-.878a2.25 2.25 0 10-1.5 0v.878a.75.75 0 01-.75.75h-4.5A.75.75 0 015 6.25v-.878zm3.75 7.378a.75.75 0 11-1.5 0 .75.75 0 011.5 0zm3-8.75a.75.75 0 100-1.5.75.75 0 000 1.5z"></path></svg></a>
              <a href="https://github.com/lidq92/SFA/network/members" class="social-count" aria-label="13 users forked this repository">13</a> /
              <a href="data/LiACMMM2017.bib">bibtex</a>
              <p></p>
              <p>High-level semantic features extracted from pre-trained image classification models help NR-IQA.</p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="http://www.vie.group/media/pdf/Blur-Specific_NR-IQA_A_Classification_and_Review_of_Representative_Methods.pdf">
                <papertitle>Blur-Specific No-Reference Image Quality Assessment: A Classification and Review of Representative Methods</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>
              <br>
              <em>Proceedings of the International Conference on Sensing and Imaging</em>, 2019 &nbsp <font color="red"><strong>(Invited Chapter)</strong></font>
              <br>
              <a href="data/LiICSI2019.bib">bibtex</a>
              <p></p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="http://www.vie.group/media/pdf/Li_et_al.-2019ZTE_Communications-Recent_Advances_and_Challenges_in_Video_Quality_Assessment.pdf">
                <papertitle>Recent Advances and Challenges in Video Quality Assessment</papertitle>
              </a>
              <br>
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>ZTE Communications</em>, 2019 &nbsp <font color="red"><strong>(Invited Paper)</strong></font>
              <br>
              <a href="data/LiZTE2019.bib">bibtex</a>
              <p></p>
            </td>
          </tr> -->

          <!-- <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1810.08339">
                <papertitle>Quality Assessment for Tone-Mapped HDR Images Using Multi-Scale and Multi-Layer Information</papertitle>
              </a>
              <br>
              <a href="">Qin He</a>, 
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>, 
              <a href='http://www.math.pku.edu.cn/teachers/jiangm/'>Ming Jiang</a>
              <br>
              <em>IEEE International Conference on Multimedia & Expo Workshop (ICMEw)</em>, 2018 &nbsp <font color="red"><strong></strong></font>
              <br>
              <a href="https://github.com/lidq92/msmlTMIQA">code</a> /
              <a href="data/LiZTE2019.bib">bibtex</a>
              <p></p>
            </td>
          </tr> -->

      <!--     <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="TODO">
                <papertitle>Rank-based Image Quality Assessment for Image Enhancement</papertitle>
              </a>
              <br>
              <a href="">Yuwen Li</a>,
              <strong>Dingquan Li</strong>, 
              <a href='http://www.vie.group/ttj'>Tingting Jiang</a>
              <br>
              submitted to <em>ACM International Conference on Multimedia (MM)</em>, 2020 &nbsp <font color="red"><strong></strong></font>
              <br>
              <p></p>
            </td>
          </tr> -->

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Academic Services</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td>
              Reviewer for TPAMI, TIP, TCSVT, TMM, TOMM, JETCAS, ICME, ICRA, ICIP, etc.
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                <a href="https://jonbarron.info">Template credit to Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
